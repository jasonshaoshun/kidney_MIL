{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_max_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12cd0579fcd84513b7728b086496f2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4967e644493a4abca7d550a22993246f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e6f51d2a22e40ecbcc7ec06c565153f",
              "IPY_MODEL_169942ee7b1940daa6ab1e8dc84e6efb"
            ]
          }
        },
        "4967e644493a4abca7d550a22993246f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e6f51d2a22e40ecbcc7ec06c565153f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8da2789ed12047ef962db196f5d84b95",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e74810b9b2641c2a69bbcf7117175ff"
          }
        },
        "169942ee7b1940daa6ab1e8dc84e6efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9feab1c533b497094c288847a7d7f1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:07&lt;00:00, 5.99MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f86006856b9408596ae955a4fa6fdc3"
          }
        },
        "8da2789ed12047ef962db196f5d84b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e74810b9b2641c2a69bbcf7117175ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9feab1c533b497094c288847a7d7f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f86006856b9408596ae955a4fa6fdc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95a1ee7a33cd444782da951732c6927d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a42d54b74e00438d9bea1281fe9d640d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_939c34518f744a55a8cb788dd8641b4a",
              "IPY_MODEL_fc3ab5934ebb4807bb5aced6628c1913"
            ]
          }
        },
        "a42d54b74e00438d9bea1281fe9d640d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "939c34518f744a55a8cb788dd8641b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8468866baa884b89b7db49a6c6b4168e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef8ec5baaa1e4c389112ff792948d517"
          }
        },
        "fc3ab5934ebb4807bb5aced6628c1913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42de22943ad14ee8b4c30c02be0f7468",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [37:37&lt;00:00, 20.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f426bd794fb497b85ab377293291bbb"
          }
        },
        "8468866baa884b89b7db49a6c6b4168e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef8ec5baaa1e4c389112ff792948d517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42de22943ad14ee8b4c30c02be0f7468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f426bd794fb497b85ab377293291bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqO5V3C7jc42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a0cc44-ff4a-45e0-ee36-eda7a5a48880"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May  7 16:22:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGqKQk_Sjj0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea63ae1-d8e0-4703-b3d0-26b947351087"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd629ESDjlJC"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xqdr0qJjkTg"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "import torch.utils.data\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "import torch.tensor as tensor\n",
        "import time\n",
        "import copy\n",
        "from torchvision import models, transforms\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from PIL import Image\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "cuda = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yeDnMZYjpPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd3d7a0-43ee-45e6-bd49-993585b2c57f"
      },
      "source": [
        "# !pip install googledrivedownloader\n",
        "# from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "# gdd.download_file_from_google_drive(file_id='13vFqjgBqTWLuBwAVSOmZ8HotckfIZjor',\n",
        "#                                     dest_path='/tmp/tcga/filtered.zip',\n",
        "#                                     unzip=True)\n",
        "# !rm /tmp/tcga/filtered.zip\n",
        "\n",
        "# https://drive.google.com/file/d/1SmsFlYp2CHndQ4Jx_ngHtQfzIT6_4wfO/view?usp=sharing\n",
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1SmsFlYp2CHndQ4Jx_ngHtQfzIT6_4wfO',\n",
        "                                    dest_path='/tmp/tcga/filtered.zip',\n",
        "                                    unzip=True)\n",
        "!rm /tmp/tcga/filtered.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "Downloading 1SmsFlYp2CHndQ4Jx_ngHtQfzIT6_4wfO into /tmp/tcga/filtered.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66EeZXZOjriE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a68844-c527-40e4-ac18-26305256d4a8"
      },
      "source": [
        "# from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "# gdd.download_file_from_google_drive(file_id='1WCQ8l-Q-BAGnOczwMXWtmtHySvROaC14',\n",
        "#                                     dest_path='/tmp/tcga/has_been_moved_and_filtered',\n",
        "#                                     unzip=False)\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1ae3IfTucMSsUNEnC-HNbAaycDjIkI1T0',\n",
        "                                    dest_path='/tmp/tcga/has_been_moved_and_filtered',\n",
        "                                    unzip=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1ae3IfTucMSsUNEnC-HNbAaycDjIkI1T0 into /tmp/tcga/has_been_moved_and_filtered... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fzSrmX6jths"
      },
      "source": [
        "# filtered_tiles_output_folder = /tmp/tcga/filtered_tiles/\n",
        "has_been_filtered_filename = \"/tmp/tcga/has_been_moved_and_filtered\"\n",
        "data_folders = open(has_been_filtered_filename, 'r').read().splitlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbbnsrWcju6A"
      },
      "source": [
        "slides_folders = list(map(lambda f: os.path.join(\"/tmp/tcga/\", f.replace(\"/Users/shunshao/Documents/GitHub/tcga_segmentation/output_folder/\", \"/tmp/tcga/\")), data_folders))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2RgqW4tjwdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb081878-e4f2-41de-cc9c-5526516c6df4"
      },
      "source": [
        "len(slides_folders)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU8a-WdDjxqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130293e2-31dc-43d6-816d-c6cd49ab188e"
      },
      "source": [
        "slides_folders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/tmp/tcga/filtered_tiles/TCGA-BP-4969-11A-01-TS1.c1c429b7-7769-48b5-b3fd-3dce5aa4c19a.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-CW-5585-01A-01-TS1.08dbf72d-9d28-4267-89d6-bfab37f33096.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-AK-3460-01A-02-BS2.effbb5e1-726b-426b-a060-5fdc565fadb9.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3387-01A-01-TS1.d0719d8d-1e96-407f-b647-06171061db34.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3365-01Z-00-DX1.dc5b8d77-b5ba-47c8-b536-a8f1ed458ed3.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3352-01A-01-TS1.d3c4f914-3145-4f6c-911f-46fd569589d1.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B8-4620-01A-01-TS1.f45ec4b6-52aa-496a-b047-3665a98a448f.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-AK-3447-01A-01-BS1.d736ff05-4908-447f-8b63-334a59540b82.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-5121-11A-01-TS1.01317588-26dd-4337-86c0-d3bfcf066c23.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B8-5552-01B-01-TS1.7cfbbaef-3cf6-4ea1-825e-b521d282b9ab.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-AS-3777-01A-01-BS1.5a03479b-afa6-43d4-829c-8500e76bcd8a.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B2-5633-01B-04-BS4.B63ED0AD-B3F7-4C32-A20D-37244BDA7E48.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-4841-01A-01-BS1.64ff8ede-1182-4836-8a9a-6b943c0085f8.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B2-5641-11A-01-TS1.eb8c4cab-1e90-4111-84d5-f4aa045b7872.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-AK-3451-01A-02-BS2.03783f75-ebbd-4dd7-baff-3ad8c2527e58.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3380-01A-01-TS1.6455da58-f102-4927-9c84-da7a3e585766.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3385-01A-01-BS1.a6db0617-fbcd-45f0-85e0-b65f5e77acd9.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-4841-11A-01-TS1.186c1682-0c95-4247-ab64-4341f33cabe9.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-5108-11A-01-TS1.b16643f5-9542-4f24-9969-536c0cb5cc0d.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-4847-01A-01-TS1.83331af8-0864-4709-98e6-9c29cd719caf.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-BP-5173-01A-01-TS1.cd7832d0-ed3b-482b-a8bd-e572c140c6d1.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-5080-11A-01-TS1.ac78ccf8-fc77-4762-9466-2207e387dce4.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-4713-11A-01-TS1.3d1c7d2d-19ab-4d2e-bb5a-8feea98d5021.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-AK-3465-01A-02-BS2.0ca60c0c-66a0-4866-8542-102586b1a3fd.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B8-4619-01A-01-BS1.fc69c5d9-a218-4922-a2d1-cc748139c6d4.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B8-4619-01A-02-BS2.f126b683-3d94-4ce0-b71f-8d4bfcd6918f.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-4838-01A-01-TS1.5815f039-af07-456c-809b-40de9f4e4e1e.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3358-01A-01-TS1.461245d8-0ac1-4bf2-8433-9414fdda0831.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-CJ-5683-11A-01-TS1.c734151a-d244-4805-bb96-a18a4e594368.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-5088-11A-01-TS1.481546e6-ba46-4c6a-9998-d7d0e0c84b74.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-5102-11A-01-TS1.1696e9bc-b42b-49ac-ba83-df21409d1f29.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-4819-01A-01-TS1.758e708e-73f4-43d5-9783-974ba16a766a.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-4837-11A-01-TS1.178b59a3-f441-4bc9-aeff-7328bad32208.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-CZ-4861-11A-01-BS1.4d4e9433-25a2-4429-a8e8-24185be1370d.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-A6NJ-11A-01-TS1.129CB7FA-9224-42F2-9F2C-9FFCA5C7445E.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3336-01A-01-TS1.a5c05841-a537-4b50-a71d-63ce5adf04fe.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-AK-3430-01A-01-BS1.1ba811d9-4ede-43f1-bfe2-b11db2e00481.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-AS-3778-01A-01-BS1.838dc562-12f5-4b3d-8dd8-9363e00e9dd9.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3373-01A-01-BS1.7a02cdfa-64e3-4a97-a7a7-2ee92a8bdf1c.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-4841-01A-01-TS1.0c375369-3a29-4104-ae17-5769766c60d8.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-AS-3777-01A-01-TS1.d1b5b7b7-aac2-44fb-815f-bde490643928.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3306-11A-01-TS1.c622542f-4cd2-4dd7-a67c-06094e11bd3f.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B2-A4SR-11A-01-TS1.E93B4BAE-0A46-4A61-8055-908050EE9546.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B8-5162-01A-01-BS1.72486129-2b25-4fe0-ba41-517823134d58.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3307-01A-01-TS1.1b385aec-9f0b-4790-a12a-75f74ccc6133.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-CW-5589-01A-01-TS1.d704b905-075c-4149-b882-0ea19a3b069f.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-B0-5094-01A-01-TS1.60bfdb27-cbf5-4b5e-9d35-393dbbfa9bb2.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-BP-5001-11A-01-TS1.460a8c71-c591-4d95-af1e-2c2fc1124664.svs',\n",
              " '/tmp/tcga/filtered_tiles/TCGA-A3-3352-01A-01-BS1.a9600d95-12d3-481d-b456-3998590c2ef1.svs']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZanLb3uHj0wQ"
      },
      "source": [
        "# 2. Build the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS-AcXrBj12K"
      },
      "source": [
        "# Dataset\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.dataset.Dataset):\n",
        "    def __init__(self, slides_folders, model_input_size, is_training, max_bag_size, logger, max_dataset_size=None,\n",
        "                 with_data_augmentation=True, seed=123, normalization_mean=None, normalization_std=None):\n",
        "        \"\"\"\n",
        "        :param slides_folders: list of abs paths of slide folder (which should contains images, summary/label/percent\n",
        "            files\n",
        "        :param model_input_size: expected model input size (for cropping)\n",
        "        :param is_training: True if is training, else False (for data augmentation)\n",
        "        :param max_bag_size: maximum number of instances to be returned per bag\n",
        "        \"\"\"\n",
        "\n",
        "        def verify_slide_folder_exists(slide_folder):\n",
        "            if not os.path.exists(slide_folder):\n",
        "                raise FileExistsError('parent dataset folder %s does not exist' % slide_folder)\n",
        "\n",
        "        list(map(verify_slide_folder_exists, slides_folders))\n",
        "\n",
        "        # self.slides_folders = np.asarray(slides_folders)\n",
        "        self.slides_folders = slides_folders\n",
        "        self.model_input_size = model_input_size\n",
        "        self.max_bag_size = max_bag_size\n",
        "        self.max_dataset_size = max_dataset_size\n",
        "\n",
        "        self.is_training = is_training\n",
        "\n",
        "        # self.logger = logger\n",
        "\n",
        "        self.slides_ids = []  # ids slides\n",
        "        self.slides_labels = []  # raw str labels\n",
        "        self.slides_summaries = []  # list of all initial tiles of slides\n",
        "        self.slides_cases = []  # list of all cases IDs\n",
        "        self.slides_images_filepaths = []  # list of all in-dataset tilespaths of slides\n",
        "\n",
        "        self.with_data_augmentation = with_data_augmentation\n",
        "        normalization_mean = (0, 0, 0) if normalization_mean is None else normalization_mean\n",
        "        normalization_std = (1, 1, 1) if normalization_std is None else normalization_std\n",
        "        self.transform = self._define_data_transforms(normalization_mean, normalization_std)\n",
        "\n",
        "        self.seed = seed\n",
        "\n",
        "        slides_ids, slides_labels, slides_summaries, slides_cases, slides_images_filepaths = self.load_data()\n",
        "        self.slides_ids = slides_ids\n",
        "        self.slides_labels = slides_labels\n",
        "        self.slides_summaries = slides_summaries\n",
        "        self.slides_cases = slides_cases\n",
        "        self.slides_images_filepaths = slides_images_filepaths\n",
        "\n",
        "        assert len(self.slides_ids) == len(self.slides_labels) == len(self.slides_summaries) == \\\n",
        "               len(self.slides_images_filepaths), 'mismatch in slides containers lengths %s' % (\n",
        "            ' '.join(str(len(l)) for l in [self.slides_ids, self.slides_labels, self.slides_summaries,\n",
        "                                           self.slides_images_filepaths]))\n",
        "\n",
        "        self.retrieve_tiles_ids_with_images = False  # True will return bag of images and associated tiles ids\n",
        "\n",
        "    def _define_data_transforms(self, mean, std):\n",
        "        if self.with_data_augmentation:\n",
        "            return transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomVerticalFlip(),\n",
        "                transforms.ColorJitter(0.1, 0.1, 0.1, 0.01),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std),\n",
        "            ])\n",
        "        return transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
        "\n",
        "    def load_data(self):\n",
        "        slides_ids, slides_labels, slides_summaries, slides_cases, slides_images_filepaths = [], [], [], [], []\n",
        "\n",
        "        # Name of expected non-image files for all slides folders\n",
        "        label_filename = 'label.txt'\n",
        "        case_id_filename = 'case_id.txt'\n",
        "        summary_filename = 'summary.txt'\n",
        "\n",
        "        # Seek all slides folders, and load static data including list of tiles filepaths and bag label\n",
        "        for i, slide_folder in enumerate(tqdm(self.slides_folders)):\n",
        "            if self.max_dataset_size is not None and i + 1 > self.max_dataset_size:\n",
        "                break\n",
        "            # print(slide_folder)\n",
        "            # a = filter(lambda f: os.path.isfile(os.path.join(slide_folder, f)), os.listdir(slide_folder))\n",
        "            # print(a)\n",
        "            # b = list(a)\n",
        "            all_slide_files = list(filter(lambda f: os.path.isfile(os.path.join(slide_folder, f)),\n",
        "                                          os.listdir(slide_folder)))\n",
        "\n",
        "            # Seek and save label, case_id and summary files: expects 1 and only 1 for each\n",
        "            for data_filename in [label_filename, case_id_filename, summary_filename]:\n",
        "                assert sum([f == data_filename for f in all_slide_files]) == 1, \\\n",
        "                    'slide %s: found %d files for %s, expected 1' % (slide_folder,\n",
        "                                                                     sum([f == data_filename for f in\n",
        "                                                                          all_slide_files], ),\n",
        "                                                                     data_filename)\n",
        "\n",
        "            label_file = os.path.join(slide_folder, [f for f in all_slide_files if f == label_filename][0])\n",
        "            case_id_file = os.path.join(slide_folder, [f for f in all_slide_files if f == case_id_filename][0])\n",
        "            summary_file = os.path.join(slide_folder, [f for f in all_slide_files if f == summary_filename][0])\n",
        "            with open(label_file, 'r') as f:\n",
        "                slide_label = int(f.read())\n",
        "            with open(case_id_file, 'r') as f:\n",
        "                slide_case_id = f.read()\n",
        "            with open(summary_file, 'r') as f:\n",
        "                slide_original_tiles = f.read().splitlines()\n",
        "\n",
        "            # Seek all filtered images of slide (not-background images)\n",
        "            slide_images_filenames = list(filter(lambda f: f.endswith(('.jpeg', '.jpg', '.png')), all_slide_files))\n",
        "\n",
        "            if len(slide_images_filenames) == 0:\n",
        "                self.logger.warning('Discarding slide %s of class %d because there are no images' %\n",
        "                                    (slide_folder, slide_label))\n",
        "                continue\n",
        "\n",
        "            # Save data\n",
        "            slides_ids.append(os.path.basename(slide_folder))\n",
        "            slides_labels.append(slide_label)\n",
        "            slides_summaries.append(slide_original_tiles)\n",
        "            slides_cases.append(slide_case_id)\n",
        "            slides_images_filepaths.append(\n",
        "                list(map(lambda f: os.path.abspath(os.path.join(slide_folder, f)), slide_images_filenames)))\n",
        "\n",
        "        slides_ids = np.asarray(slides_ids)\n",
        "        slides_labels = np.asarray(slides_labels)\n",
        "        print(\"end\\n\")\n",
        "\n",
        "        return slides_ids, slides_labels, slides_summaries, slides_cases, slides_images_filepaths\n",
        "\n",
        "    # def show_bag(self, bag_idx, savefolder=None):\n",
        "    #     \"\"\" Plot/save tiles sampled from the slide of provided index \"\"\"\n",
        "    #     bag = self._get_slide_instances(bag_idx)\n",
        "    #     bag_label = self.slides_labels[bag_idx]\n",
        "    #     tr = transforms.ToTensor()\n",
        "    #     bag = [tr(b) for b in bag]\n",
        "    #     imgs = make_grid(bag)\n",
        "\n",
        "    #     npimgs = imgs.numpy()\n",
        "    #     plt.imshow(np.transpose(npimgs, (1, 2, 0)), interpolation='nearest')\n",
        "    #     plt.title('Bag label: %s | %d instances' % (bag_label, len(bag)))\n",
        "    #     if savefolder is not None:\n",
        "    #         plt.savefig(os.path.join(savefolder, 'show_' + str(bag_idx) + '.png'), dpi=1000)\n",
        "    #     else:\n",
        "    #         plt.show()\n",
        "\n",
        "    def _get_slide_instances(self, item):\n",
        "        \"\"\" Memory load all tiles or randomly sampled tiles from slide of specified index \"\"\"\n",
        "        slide_images_filepaths = self.slides_images_filepaths[item]\n",
        "\n",
        "        # Randomly sample the specified max number of tiles from the slide with replacement\n",
        "        if self.max_bag_size is not None:\n",
        "            slide_images_filepaths = random.choices(slide_images_filepaths, k=self.max_bag_size)\n",
        "\n",
        "        # Load images\n",
        "        bag_images = [pil_loader(slide_image_filepath) for slide_image_filepath in slide_images_filepaths]\n",
        "\n",
        "        if self.retrieve_tiles_ids_with_images:\n",
        "            # return bag of images as well as the associated ids of the tiles\n",
        "            return bag_images, list(map(os.path.basename, slide_images_filepaths)), self.slides_summaries[item]\n",
        "        return bag_images\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if not self.retrieve_tiles_ids_with_images:\n",
        "            slide_instances = self._get_slide_instances(item)\n",
        "            slide_instances = torch.stack([self.transform(instance) for instance in slide_instances])\n",
        "            slide_label = self.slides_labels[item]\n",
        "            return slide_instances, slide_label\n",
        "\n",
        "        slide_instances, tiles_ids, slide_summary = self._get_slide_instances(item)\n",
        "        slide_instances = torch.stack([self.transform(instance) for instance in slide_instances])\n",
        "        slide_label = self.slides_labels[item]\n",
        "        return slide_instances, slide_label, tiles_ids, slide_summary\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slides_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9s1rJdLj_FL"
      },
      "source": [
        "import random\n",
        "\n",
        "def split_svs_samples_casewise(svs_files, associated_cases_ids, val_size, test_size, seed=123):\n",
        "    assert len(svs_files) == len(associated_cases_ids), 'Expected same number of SVS files than associated case ID'\n",
        "    random.seed(seed)\n",
        "    train_size = 1. - val_size - test_size\n",
        "\n",
        "    unique_cases_ids = list(set(associated_cases_ids))\n",
        "    random.shuffle(unique_cases_ids)\n",
        "    total_unique_cases_ids = len(unique_cases_ids)\n",
        "\n",
        "    # Extract cases ids for training, validation and testing sets\n",
        "    train_cases_ids = unique_cases_ids[:int(train_size*total_unique_cases_ids)]\n",
        "    val_cases_ids = unique_cases_ids[int(train_size*total_unique_cases_ids):\n",
        "                                     int(train_size*total_unique_cases_ids)+int(val_size*total_unique_cases_ids)]\n",
        "    test_cases_ids = unique_cases_ids[int(train_size*total_unique_cases_ids)+int(val_size*total_unique_cases_ids):]\n",
        "    assert len(train_cases_ids) + len(val_cases_ids) + len(test_cases_ids) == total_unique_cases_ids\n",
        "\n",
        "    # Compute associated split set for SVS files\n",
        "    train_svs_files, val_svs_files, test_svs_files = [], [], []\n",
        "    for svs_file, associated_case_id in zip(svs_files, associated_cases_ids):\n",
        "        if associated_case_id in train_cases_ids:\n",
        "            train_svs_files.append(svs_file)\n",
        "        elif associated_case_id in val_cases_ids:\n",
        "            val_svs_files.append(svs_file)\n",
        "        else:\n",
        "            test_svs_files.append(svs_file)\n",
        "\n",
        "    return train_svs_files, val_svs_files, test_svs_files\n",
        "\n",
        "def build_datasets(source_slides_folders, model_input_width, hyper_parameters, logger):\n",
        "    normalization_channels_mean = (0.6387467, 0.51136744, 0.6061169)\n",
        "    normalization_channels_std = (0.31200314, 0.3260718, 0.30386254)\n",
        "\n",
        "    # First load all data into a single Dataset\n",
        "    whole_dataset = Dataset(slides_folders=source_slides_folders, model_input_size=model_input_width,\n",
        "                            is_training=False, max_bag_size=hyper_parameters['max_bag_size'],\n",
        "                            logger=logger, max_dataset_size=hyper_parameters['dataset_max_size'],\n",
        "                            with_data_augmentation=hyper_parameters['with_data_augmentation'],\n",
        "                            seed=hyper_parameters['seed'],\n",
        "                            normalization_mean=normalization_channels_mean,\n",
        "                            normalization_std=normalization_channels_std)\n",
        "    whole_cases_ids = whole_dataset.slides_cases\n",
        "    whole_indexes = list(range(len(whole_dataset)))\n",
        "\n",
        "    val_size = hyper_parameters['val_size']\n",
        "    test_size = hyper_parameters['test_size']\n",
        "    train_idx, val_idx, test_idx = split_svs_samples_casewise(whole_indexes, whole_cases_ids,\n",
        "                                                              val_size=val_size, test_size=test_size,\n",
        "                                                              seed=hyper_parameters['seed'])\n",
        "\n",
        "    val_dataset = torch.utils.data.Subset(whole_dataset, val_idx)\n",
        "    test_dataset = torch.utils.data.Subset(whole_dataset, test_idx)\n",
        "    train_dataset = torch.utils.data.Subset(whole_dataset, train_idx)\n",
        "    train_dataset.dataset.is_training = True\n",
        "    train_dataset.dataset.transform = train_dataset.dataset._define_data_transforms(normalization_channels_mean,\n",
        "                                                                                    normalization_channels_std)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset, whole_cases_ids, whole_indexes, whole_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mWDw88okHRX"
      },
      "source": [
        "# 1.Review on Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeTpvcrfkAc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "12cd0579fcd84513b7728b086496f2c0",
            "4967e644493a4abca7d550a22993246f",
            "1e6f51d2a22e40ecbcc7ec06c565153f",
            "169942ee7b1940daa6ab1e8dc84e6efb",
            "8da2789ed12047ef962db196f5d84b95",
            "2e74810b9b2641c2a69bbcf7117175ff",
            "b9feab1c533b497094c288847a7d7f1f",
            "5f86006856b9408596ae955a4fa6fdc3"
          ]
        },
        "outputId": "3f17f301-48eb-4efc-eb0b-b7752c2f0d24"
      },
      "source": [
        "rn18 = models.resnet18(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12cd0579fcd84513b7728b086496f2c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp72FsgEkJ5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f75ac2e-46eb-42db-dc14-4b23d91455de"
      },
      "source": [
        "children_counter = 0\n",
        "for n,c in rn18.named_children():\n",
        "    print(\"Children Counter: \",children_counter,\" Layer Name: \",n,)\n",
        "    children_counter+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Children Counter:  0  Layer Name:  conv1\n",
            "Children Counter:  1  Layer Name:  bn1\n",
            "Children Counter:  2  Layer Name:  relu\n",
            "Children Counter:  3  Layer Name:  maxpool\n",
            "Children Counter:  4  Layer Name:  layer1\n",
            "Children Counter:  5  Layer Name:  layer2\n",
            "Children Counter:  6  Layer Name:  layer3\n",
            "Children Counter:  7  Layer Name:  layer4\n",
            "Children Counter:  8  Layer Name:  avgpool\n",
            "Children Counter:  9  Layer Name:  fc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI1uOz-BkL1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164696b0-b69a-4711-adfa-fb59996ba998"
      },
      "source": [
        "rn18._modules"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('conv1',\n",
              "              Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n",
              "             ('bn1',\n",
              "              BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('relu', ReLU(inplace=True)),\n",
              "             ('maxpool',\n",
              "              MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n",
              "             ('layer1', Sequential(\n",
              "                (0): BasicBlock(\n",
              "                  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "                (1): BasicBlock(\n",
              "                  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )),\n",
              "             ('layer2', Sequential(\n",
              "                (0): BasicBlock(\n",
              "                  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (downsample): Sequential(\n",
              "                    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  )\n",
              "                )\n",
              "                (1): BasicBlock(\n",
              "                  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )),\n",
              "             ('layer3', Sequential(\n",
              "                (0): BasicBlock(\n",
              "                  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (downsample): Sequential(\n",
              "                    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  )\n",
              "                )\n",
              "                (1): BasicBlock(\n",
              "                  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )),\n",
              "             ('layer4', Sequential(\n",
              "                (0): BasicBlock(\n",
              "                  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (downsample): Sequential(\n",
              "                    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  )\n",
              "                )\n",
              "                (1): BasicBlock(\n",
              "                  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )),\n",
              "             ('avgpool', AdaptiveAvgPool2d(output_size=(1, 1))),\n",
              "             ('fc', Linear(in_features=512, out_features=1000, bias=True))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_OEiqaQkNQ7"
      },
      "source": [
        "class new_model(nn.Module):\n",
        "    def __init__(self,output_layer = None):\n",
        "        super().__init__()\n",
        "        self.pretrained = models.resnet18(pretrained=True)\n",
        "        self.output_layer = output_layer\n",
        "        self.layers = list(self.pretrained._modules.keys())\n",
        "        self.layer_count = 0\n",
        "        for l in self.layers:\n",
        "            if l != self.output_layer:\n",
        "                self.layer_count += 1\n",
        "            else:\n",
        "                break\n",
        "        for i in range(1,len(self.layers)-self.layer_count):\n",
        "            self.dummy_var = self.pretrained._modules.pop(self.layers[-i])\n",
        "        \n",
        "        self.net = nn.Sequential(self.pretrained._modules)\n",
        "        self.pretrained = None\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.net(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmmHys8-kPQB"
      },
      "source": [
        "model = new_model(output_layer = 'layer4')\n",
        "cuda = torch.device('cuda:0')\n",
        "model = model.to(cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMjDTLBdkR3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa29106-1834-46a1-a4ed-4fdb51a4f821"
      },
      "source": [
        "summary(model,input_size=(3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "================================================================\n",
            "Total params: 11,176,512\n",
            "Trainable params: 11,176,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.78\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 105.99\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLX08mFnkTgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2a2ee9-46b0-48da-b89f-6405b9053765"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new_model(\n",
            "  (pretrained): None\n",
            "  (dummy_var): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (net): Sequential(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iUu2-_jkXpr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nto6GFcLmjT5"
      },
      "source": [
        "# 2.Max-MIL (Resnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl0f8eWumq_j"
      },
      "source": [
        "## Dataset split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntb11xgRmf4x"
      },
      "source": [
        "hyper_parameters = {\n",
        "    # Training Control Parameters\n",
        "    \n",
        "    # Dataset Parameters\n",
        "    'max_bag_size': 200,\n",
        "    'dataset_max_size': None,\n",
        "    'with_data_augmentation': False,\n",
        "    # 'with_tensorboard': not args.no_tensorboard,\n",
        "    'seed': 123,\n",
        "    'val_size': 0.15,\n",
        "    'test_size': 0,\n",
        "    # 'val_size': 0.02,\n",
        "    # 'test_size': 0.95,\n",
        "}\n",
        "\n",
        "logger = None\n",
        "input_width = 224\n",
        "train_dataset, val_dataset, test_dataset, whole_cases_ids, whole_indexes, whole_dataset = build_datasets(source_slides_folders=slides_folders,\n",
        "                                                              model_input_width=input_width,\n",
        "                                                              hyper_parameters=hyper_parameters,\n",
        "                                                              logger=logger)\n",
        "N_PROCESSES = 5\n",
        "def to_dataloader(dataset, for_training):\n",
        "    assert isinstance(dataset, Dataset) or isinstance(dataset, torch.utils.data.Subset)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=for_training, num_workers=N_PROCESSES)\n",
        "\n",
        "train_dataloader = to_dataloader(train_dataset, True)\n",
        "val_dataloader = to_dataloader(val_dataset, False) if len(val_dataset) else None\n",
        "test_dataloader = to_dataloader(test_dataset, False) if len(test_dataset) else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIuKYYecmubX"
      },
      "source": [
        "train_carcinoma = 0\n",
        "train_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(train_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      train_carcinoma += 1\n",
        "    else:\n",
        "      train_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the training set\" %(train_carcinoma, train_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "val_carcinoma = 0\n",
        "val_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(val_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      val_carcinoma += 1\n",
        "    else:\n",
        "      val_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the validation set\" %(val_carcinoma, val_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "test_carcinoma = 0\n",
        "test_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(test_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      test_carcinoma += 1\n",
        "    else:\n",
        "      test_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the test set\" %(test_carcinoma, test_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vW6w8DNmzN9"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFnkaV_Smwzf"
      },
      "source": [
        "class max_resnet(nn.Module):\n",
        "    def __init__(self,output_layer = None):\n",
        "        super().__init__()\n",
        "        self.pretrained = models.resnet18(pretrained=True)\n",
        "        self.output_layer = output_layer\n",
        "        self.layers = list(self.pretrained._modules.keys())\n",
        "        self.layer_count = 0\n",
        "        for l in self.layers:\n",
        "            if l != self.output_layer:\n",
        "                self.layer_count += 1\n",
        "            else:\n",
        "                break\n",
        "        for i in range(1,len(self.layers)-self.layer_count):\n",
        "            self.dummy_var = self.pretrained._modules.pop(self.layers[-i])\n",
        "        \n",
        "        self.net = nn.Sequential(self.pretrained._modules)\n",
        "        self.pretrained = None\n",
        "\n",
        "        self.L = 500\n",
        "\n",
        "# N, 512, 7, 7\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, self.L),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.L, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.squeeze(0)\n",
        "        x = self.net(x)\n",
        "        # print(\"x size 1\")\n",
        "        # print(x.size())\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "\n",
        "        H = self.feature_extractor(x)\n",
        "        \n",
        "        H, _ = torch.max(H, 0)\n",
        "        # print(H.size())\n",
        "        A = 0\n",
        "\n",
        "        Y_prob = self.classifier(H)\n",
        "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
        "\n",
        "        return Y_prob, Y_hat, A\n",
        "    \n",
        "    # AUXILIARY METHODS\n",
        "    def calculate_classification_error(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        _, Y_hat, _ = self.forward(X)\n",
        "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
        "\n",
        "        return error, Y_hat\n",
        "\n",
        "    def calculate_objective(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        Y_prob_roc, _, A = self.forward(X)\n",
        "        Y_prob = torch.clamp(Y_prob_roc, min=1e-5, max=1. - 1e-5)\n",
        "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
        "\n",
        "        return neg_log_likelihood, A, Y_prob_roc.detach().cpu().float()\n",
        "    \n",
        "    # AUXILIARY METHODS\n",
        "    def calculate_classification_error_and_objective(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        Y_prob_roc, Y_hat, A = self.forward(X)\n",
        "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
        "        Y_prob = torch.clamp(Y_prob_roc, min=1e-5, max=1. - 1e-5)\n",
        "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
        "\n",
        "\n",
        "        return neg_log_likelihood, A, Y_prob_roc.detach().cpu().float(), error, Y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7upuYbDIm2aS"
      },
      "source": [
        "model = max_resnet(output_layer = 'layer4')\n",
        "cuda = torch.device('cuda:0')\n",
        "model = model.to(cuda)\n",
        "summary(model,input_size=(3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-_lEG19m4U7"
      },
      "source": [
        "print(model)\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLsXS1xdm64G"
      },
      "source": [
        "## Train and Test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYy34MZUm89Z"
      },
      "source": [
        "def train(model, optimizer, train_loader, val_loader, writer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_size = train_loader.dataset.__len__()\n",
        "    val_size = val_loader.dataset.__len__()\n",
        "    print(f\"the number of training sample is {train_size}, the number of valisation sample is {val_size}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        expect_fpr = np.zeros((num_epochs, 1))\n",
        "        expect_tpr = np.zeros((num_epochs, 1))\n",
        "        roc_fpr = np.zeros((3, num_epochs))\n",
        "        roc_tpr = np.zeros((3, num_epochs))\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            train_loss = 0.\n",
        "            train_error = 0.\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            # running_loss = 0.0\n",
        "            # running_corrects = 0\n",
        "            # dataset_size_count = 0\n",
        "\n",
        "            true_positve = 0.0\n",
        "            false_positive = 0.0\n",
        "            true_negative = 0.0\n",
        "            false_negative = 0.0\n",
        "            y_true = []\n",
        "            y_predict = []\n",
        "\n",
        "            # Iterate over data.\n",
        "            for batch_idx, (data, bag_label) in enumerate(dataloader):\n",
        "            # for inputs, labels in dataloader:\n",
        "                print(phase + \" start\")\n",
        "                # dataset_size_count += data.shape[0]\n",
        "                # # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                data, bag_label = data.cuda(), bag_label.cuda()\n",
        "                # data, bag_label = data.to(dev), bag_label.to(dev)\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # calculate loss and metrics\n",
        "                    # loss, _, Y_prob_roc = model.calculate_objective(data, bag_label)\n",
        "                    # train_loss += loss.data[0].cpu().float()\n",
        "\n",
        "                    # error, _ = model.calculate_classification_error(data, bag_label)\n",
        "                    # train_error += error\n",
        "\n",
        "                    loss, _, Y_prob_roc, error, _ = model.calculate_classification_error_and_objective(data, bag_label)\n",
        "                    train_loss += loss.data[0].cpu().float()\n",
        "                    train_error += error\n",
        "\n",
        "                    if bag_label == 1:\n",
        "                      y_true.append(1)\n",
        "                      if error == 0.0:\n",
        "                        true_positve += 1\n",
        "                      elif error == 1.0:\n",
        "                        false_positive += 1\n",
        "                    elif bag_label == 0:\n",
        "                      y_true.append(0)\n",
        "                      if error == 0.0:\n",
        "                        true_negative += 1\n",
        "                      elif error == 1.0:\n",
        "                        false_negative += 1\n",
        "                    # print(Y_prob_roc)\n",
        "                    y_predict.append(Y_prob_roc)\n",
        "                    \n",
        "                    # print(\"free memory\")\n",
        "                    del data, bag_label\n",
        "                    \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "            print(f\"End of phase: the true positve is {true_positve}, false positive is {false_positive}, true negative is {true_negative}, false negative is {false_negative}\")\n",
        "            # if phase == 'train':\n",
        "            #   try:\n",
        "            #     print(f\"Explicit result: fpr is {true_negative/(true_negative + false_positive)}, tpr is {true_positve/(true_positve + false_negative)}\")\n",
        "            #     expect_fpr[epoch] = (true_negative/(true_negative + false_positive))\n",
        "            #     expect_tpr[epoch] = (true_positve/(true_positve + false_negative))\n",
        "            #     print(f\"y_true is {y_true}, y_predict is {y_predict}\")\n",
        "            #   except ZeroDivisionError:\n",
        "            #     print(\"zero devision occurs\")\n",
        "            \n",
        "            fpr, tpr, _ = roc_curve(y_true, y_predict)\n",
        "            print(f\"Roc calculation result: fpr is {fpr}, tpr is {tpr}\")\n",
        "            # roc_fpr[:, epoch] = fpr\n",
        "            # roc_tpr[:, epoch] = tpr\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.figure()\n",
        "            lw = 2\n",
        "            plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "            plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "            plt.xlim([0.0, 1.0])\n",
        "            plt.ylim([0.0, 1.05])\n",
        "            plt.xlabel('False Positive Rate')\n",
        "            plt.ylabel('True Positive Rate')\n",
        "            plt.title('Receiver operating characteristic example')\n",
        "            plt.legend(loc=\"lower right\")\n",
        "            plt.show()\n",
        "            \n",
        "\n",
        "\n",
        "            #   # if phase == 'train':\n",
        "            #   #     scheduler.step()\n",
        "\n",
        "            # dataset_sizes = dataloader.dataset.__len__()\n",
        "            # epoch_loss = running_loss / dataset_sizes\n",
        "            # # epoch_acc = running_corrects.double() / dataset_sizes\n",
        "            # epoch_acc = running_corrects / dataset_size_count\n",
        "            \n",
        "            # # print('Phase {}'.format(phase))\n",
        "            # # print(\"Loss: \")\n",
        "            # # print(train_loss)\n",
        "            # # print(\"Error: \")\n",
        "            # # print(train_error)\n",
        "\n",
        "            # # print('{} Loss: {:.4f} error: {:.4f} by Size: {:.4f}'.format(\n",
        "            # #     phase, train_loss, train_error, dataset_sizes))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val':\n",
        "              epoch_phase_acc = 1 - (train_error / dataloader.dataset.__len__())\n",
        "              if epoch_phase_acc > best_acc:\n",
        "                print(f\"epoch_phase_acc is {epoch_phase_acc}\")\n",
        "                best_acc = epoch_phase_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            with writer.as_default():\n",
        "              if phase == 'val':\n",
        "                tf.summary.scalar('Loss/Validation', train_loss, step=epoch)\n",
        "                tf.summary.scalar('Error/Validation', train_error, step=epoch)\n",
        "              else:\n",
        "                tf.summary.scalar('Loss/Train', train_loss, step=epoch)\n",
        "                tf.summary.scalar('Error/Train', train_error, step=epoch)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    writer.close()\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWaYnECRm_Ej"
      },
      "source": [
        "def test(model, optimizer, test_loader):\n",
        "    since = time.time()\n",
        "    test_size = test_loader.dataset.__len__()\n",
        "    print(f\"the number of test sample is {test_size}\")\n",
        "\n",
        "\n",
        "    # Test phase\n",
        "\n",
        "    train_error = 0.0\n",
        "    true_positve = 0.0\n",
        "    false_positive = 0.0\n",
        "    true_negative = 0.0\n",
        "    false_negative = 0.0\n",
        "    y_true = []\n",
        "    y_predict = []\n",
        "    for batch_idx, (data, bag_label) in enumerate(test_loader):\n",
        "        print(\"test start\")\n",
        "        optimizer.zero_grad()\n",
        "        data, bag_label = data.cuda(), bag_label.cuda()\n",
        "        with torch.no_grad():\n",
        "            loss, _, Y_prob_roc, error, _ = model.calculate_classification_error_and_objective(data, bag_label)\n",
        "            train_error += error\n",
        "            if bag_label == 1:\n",
        "              y_true.append(1)\n",
        "              if error == 0.0:\n",
        "                true_positve += 1\n",
        "              elif error == 1.0:\n",
        "                false_positive += 1\n",
        "            elif bag_label == 0:\n",
        "              y_true.append(0)\n",
        "              if error == 0.0:\n",
        "                true_negative += 1\n",
        "              elif error == 1.0:\n",
        "                false_negative += 1\n",
        "            # print(Y_prob_roc)\n",
        "            y_predict.append(Y_prob_roc)\n",
        "\n",
        "            # print(\"free memory\")\n",
        "            del data, bag_label\n",
        "    print(f\"End of phase: the true positve is {true_positve}, false positive is {false_positive}, true negative is {true_negative}, false negative is {false_negative}\")\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_predict)\n",
        "    print(f\"Roc calculation result: fpr is {fpr}, tpr is {tpr}\")\n",
        "    # roc_fpr[:, epoch] = fpr\n",
        "    # roc_tpr[:, epoch] = tpr\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    test_acc = 1 - (train_error / test_loader.dataset.__len__())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Test complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Test Acc: {:4f}'.format(test_acc))\n",
        "    # load best model weights\n",
        "    # model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neg5oen5nDxN"
      },
      "source": [
        "## 5e-8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAttGMIbnMO6"
      },
      "source": [
        "log_dir = 'logs/learning_rate/max_Resnet/lr=5e-8'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = max_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-8, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PsyrWF0nFEk"
      },
      "source": [
        "## 5e-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxZ5c_KbnNMZ"
      },
      "source": [
        "log_dir = 'logs/learning_rate/max_Resnet/lr=5e-7'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = max_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-7, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU_hg1dKnFwC"
      },
      "source": [
        "## 5e-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v978n9J0nQRD"
      },
      "source": [
        "log_dir = 'logs/learning_rate/max_Resnet/lr=5e-6'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = max_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-6, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GejO2XqNnGbR"
      },
      "source": [
        "## 5e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GrUqT9znJWX"
      },
      "source": [
        "log_dir = 'logs/learning_rate/max_Resnet/lr=5e-5'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = max_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHKFwdMInX2I"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "%tensorboard --logdir logs/learning_rate/max_Resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGm7DegBncWz"
      },
      "source": [
        "## Full Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhjBGT7aneDQ"
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
        "log_dir = 'logs/full_epochs/' + current_time + '/max_Resnet/lr=5e-6'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "model = max_resnet(output_layer = 'layer4')\n",
        "\n",
        "model = model.to(cuda)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-6, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD68qChAnfCR"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/full_epochs/0427-1536/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN0zoy56niVO"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oji2THoxnj54"
      },
      "source": [
        "hyper_parameters = {\n",
        "    # Training Control Parameters\n",
        "    \n",
        "    # Dataset Parameters\n",
        "    'max_bag_size': 200,\n",
        "    'dataset_max_size': None,\n",
        "    'with_data_augmentation': False,\n",
        "    # 'with_tensorboard': not args.no_tensorboard,\n",
        "    'seed': 123,\n",
        "    # 'val_size': 0.15,\n",
        "    # 'test_size': 0,\n",
        "    'val_size': 0.02,\n",
        "    'test_size': 0.95,\n",
        "}\n",
        "\n",
        "logger = None\n",
        "input_width = 224\n",
        "train_dataset, val_dataset, test_dataset, whole_cases_ids, whole_indexes, whole_dataset = build_datasets(source_slides_folders=slides_folders,\n",
        "                                                              model_input_width=input_width,\n",
        "                                                              hyper_parameters=hyper_parameters,\n",
        "                                                              logger=logger)\n",
        "N_PROCESSES = 5\n",
        "def to_dataloader(dataset, for_training):\n",
        "    assert isinstance(dataset, Dataset) or isinstance(dataset, torch.utils.data.Subset)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=for_training, num_workers=N_PROCESSES)\n",
        "\n",
        "train_dataloader = to_dataloader(train_dataset, True)\n",
        "val_dataloader = to_dataloader(val_dataset, False) if len(val_dataset) else None\n",
        "test_dataloader = to_dataloader(test_dataset, False) if len(test_dataset) else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HSb_pZBnlcD"
      },
      "source": [
        "train_carcinoma = 0\n",
        "train_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(train_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      train_carcinoma += 1\n",
        "    else:\n",
        "      train_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the training set\" %(train_carcinoma, train_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "val_carcinoma = 0\n",
        "val_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(val_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      val_carcinoma += 1\n",
        "    else:\n",
        "      val_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the validation set\" %(val_carcinoma, val_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "test_carcinoma = 0\n",
        "test_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(test_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      test_carcinoma += 1\n",
        "    else:\n",
        "      test_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the test set\" %(test_carcinoma, test_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWFXKoGZnnDI"
      },
      "source": [
        "final = test(return_model, optimizer, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1UoKlfBn1D2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb9ae5-Skgab"
      },
      "source": [
        "# 3.Attention-MIL (Lenet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRcGhYEWy5BI"
      },
      "source": [
        "def train_attention(model, optimizer, train_loader, val_loader, writer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_size = train_loader.dataset.__len__()\n",
        "    val_size = val_loader.dataset.__len__()\n",
        "    print(f\"the number of training sample is {train_size}, the number of valisation sample is {val_size}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        expect_fpr = np.zeros((num_epochs, 1))\n",
        "        expect_tpr = np.zeros((num_epochs, 1))\n",
        "        roc_fpr = np.zeros((3, num_epochs))\n",
        "        roc_tpr = np.zeros((3, num_epochs))\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            train_loss = 0.\n",
        "            train_error = 0.\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            # running_loss = 0.0\n",
        "            # running_corrects = 0\n",
        "            # dataset_size_count = 0\n",
        "\n",
        "            true_positve = 0.0\n",
        "            false_positive = 0.0\n",
        "            true_negative = 0.0\n",
        "            false_negative = 0.0\n",
        "            y_true = []\n",
        "            y_predict = []\n",
        "\n",
        "            # Iterate over data.\n",
        "            for batch_idx, (data, bag_label) in enumerate(dataloader):\n",
        "            # for inputs, labels in dataloader:\n",
        "                print(phase + \" start\")\n",
        "                # dataset_size_count += data.shape[0]\n",
        "                # # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                data, bag_label = data.cuda(), bag_label.cuda()\n",
        "                # data, bag_label = data.to(dev), bag_label.to(dev)\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # calculate loss and metrics\n",
        "                    # loss, _, Y_prob_roc = model.calculate_objective(data, bag_label)\n",
        "                    # train_loss += loss.data[0].cpu().float()\n",
        "\n",
        "                    # error, _ = model.calculate_classification_error(data, bag_label)\n",
        "                    # train_error += error\n",
        "\n",
        "                    loss, _, Y_prob_roc, error, _ = model.calculate_classification_error_and_objective(data, bag_label)\n",
        "                    # print(f\"loss is {loss}\")\n",
        "                    train_loss += torch.squeeze(loss.data[0]).cpu().float()\n",
        "                    # print(f\"trin loss is {train_loss}\")\n",
        "                    train_error += error\n",
        "\n",
        "                    if bag_label == 1:\n",
        "                      y_true.append(1)\n",
        "                      if error == 0.0:\n",
        "                        true_positve += 1\n",
        "                      elif error == 1.0:\n",
        "                        false_positive += 1\n",
        "                    elif bag_label == 0:\n",
        "                      y_true.append(0)\n",
        "                      if error == 0.0:\n",
        "                        true_negative += 1\n",
        "                      elif error == 1.0:\n",
        "                        false_negative += 1\n",
        "                    # print(Y_prob_roc)\n",
        "                    y_predict.append(Y_prob_roc)\n",
        "                    \n",
        "                    # print(\"free memory\")\n",
        "                    del data, bag_label\n",
        "                    \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "            print(f\"End of phase: the true positve is {true_positve}, false positive is {false_positive}, true negative is {true_negative}, false negative is {false_negative}\")\n",
        "            # if phase == 'train':\n",
        "            #   try:\n",
        "            #     print(f\"Explicit result: fpr is {true_negative/(true_negative + false_positive)}, tpr is {true_positve/(true_positve + false_negative)}\")\n",
        "            #     expect_fpr[epoch] = (true_negative/(true_negative + false_positive))\n",
        "            #     expect_tpr[epoch] = (true_positve/(true_positve + false_negative))\n",
        "            #     print(f\"y_true is {y_true}, y_predict is {y_predict}\")\n",
        "            #   except ZeroDivisionError:\n",
        "            #     print(\"zero devision occurs\")\n",
        "            \n",
        "            fpr, tpr, _ = roc_curve(y_true, y_predict)\n",
        "            print(f\"Roc calculation result: fpr is {fpr}, tpr is {tpr}\")\n",
        "            # roc_fpr[:, epoch] = fpr\n",
        "            # roc_tpr[:, epoch] = tpr\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.figure()\n",
        "            lw = 2\n",
        "            plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "            plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "            plt.xlim([0.0, 1.0])\n",
        "            plt.ylim([0.0, 1.05])\n",
        "            plt.xlabel('False Positive Rate')\n",
        "            plt.ylabel('True Positive Rate')\n",
        "            plt.title('Receiver operating characteristic example')\n",
        "            plt.legend(loc=\"lower right\")\n",
        "            plt.show()\n",
        "            #   # if phase == 'train':\n",
        "            #   #     scheduler.step()\n",
        "\n",
        "            # dataset_sizes = dataloader.dataset.__len__()\n",
        "            # epoch_loss = running_loss / dataset_sizes\n",
        "            # # epoch_acc = running_corrects.double() / dataset_sizes\n",
        "            # epoch_acc = running_corrects / dataset_size_count\n",
        "            \n",
        "            # # print('Phase {}'.format(phase))\n",
        "            # # print(\"Loss: \")\n",
        "            # # print(train_loss)\n",
        "            # # print(\"Error: \")\n",
        "            # # print(train_error)\n",
        "\n",
        "            # # print('{} Loss: {:.4f} error: {:.4f} by Size: {:.4f}'.format(\n",
        "            # #     phase, train_loss, train_error, dataset_sizes))\n",
        "            epoch_phase_acc = 1 - (train_error / dataloader.dataset.__len__())\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val':\n",
        "              epoch_phase_acc = 1 - (train_error / dataloader.dataset.__len__())\n",
        "              if epoch_phase_acc > best_acc:\n",
        "                print(f\"better epoch_phase_acc is {epoch_phase_acc}\")\n",
        "                best_acc = epoch_phase_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            # print(f\"train loss before {train_loss}\")\n",
        "            # train_loss = torch.squeeze(train_loss)\n",
        "            # print(f\"train loss after {train_loss}\")\n",
        "            with writer.as_default():\n",
        "              if phase == 'val':\n",
        "                tf.summary.scalar('Loss/Validation', train_loss, step=epoch)\n",
        "                tf.summary.scalar('Error/Validation', train_error, step=epoch)\n",
        "              else:\n",
        "                tf.summary.scalar('Loss/Train', train_loss, step=epoch)\n",
        "                tf.summary.scalar('Error/Train', train_error, step=epoch)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    writer.close()\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bPlMFyE1ryi"
      },
      "source": [
        "## Dataset split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5w0mNid1xIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fd0a76-767c-4a53-f829-3f9ef6bde9e2"
      },
      "source": [
        "hyper_parameters = {\n",
        "    # Training Control Parameters\n",
        "    \n",
        "    # Dataset Parameters\n",
        "    'max_bag_size': 200,\n",
        "    'dataset_max_size': None,\n",
        "    'with_data_augmentation': False,\n",
        "    # 'with_tensorboard': not args.no_tensorboard,\n",
        "    'seed': 123,\n",
        "    'val_size': 0.15,\n",
        "    'test_size': 0,\n",
        "    # 'val_size': 0.02,\n",
        "    # 'test_size': 0.95,\n",
        "}\n",
        "\n",
        "logger = None\n",
        "input_width = 224\n",
        "train_dataset, val_dataset, test_dataset, whole_cases_ids, whole_indexes, whole_dataset = build_datasets(source_slides_folders=slides_folders,\n",
        "                                                              model_input_width=input_width,\n",
        "                                                              hyper_parameters=hyper_parameters,\n",
        "                                                              logger=logger)\n",
        "N_PROCESSES = 5\n",
        "def to_dataloader(dataset, for_training):\n",
        "    assert isinstance(dataset, Dataset) or isinstance(dataset, torch.utils.data.Subset)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=for_training, num_workers=N_PROCESSES)\n",
        "\n",
        "train_dataloader = to_dataloader(train_dataset, True)\n",
        "val_dataloader = to_dataloader(val_dataset, False) if len(val_dataset) else None\n",
        "test_dataloader = to_dataloader(test_dataset, False) if len(test_dataset) else None\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 49/49 [00:00<00:00, 57.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "end\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmGNpxMU1uqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5961eea4-f040-45e1-b784-f197a91fd54b"
      },
      "source": [
        "train_carcinoma = 0\n",
        "train_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(train_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      train_carcinoma += 1\n",
        "    else:\n",
        "      train_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the training set\" %(train_carcinoma, train_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "val_carcinoma = 0\n",
        "val_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(val_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      val_carcinoma += 1\n",
        "    else:\n",
        "      val_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the validation set\" %(val_carcinoma, val_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "test_carcinoma = 0\n",
        "test_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(test_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      test_carcinoma += 1\n",
        "    else:\n",
        "      test_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the test set\" %(test_carcinoma, test_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "There are 13 carcinoma and 27 non-carcinoma samples in the training set\n",
            "There are 3 carcinoma and 5 non-carcinoma samples in the validation set\n",
            "There are 0 carcinoma and 1 non-carcinoma samples in the test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APZ7Xjje1yY2"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrk466NYkipU"
      },
      "source": [
        "class attention_lenet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(attention_lenet, self).__init__()\n",
        "        self.L = 500\n",
        "        self.D = 128\n",
        "        self.K = 1\n",
        "\n",
        "        self.feature_extractor_part1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(20, 50, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2)\n",
        "        )\n",
        "\n",
        "        # self.feature_extractor_part1 = nn.Sequential(\n",
        "        #     nn.Conv2d(1, 20, kernel_size=5),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.MaxPool2d(2, stride=2),\n",
        "        #     nn.Conv2d(20, 50, kernel_size=5),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.MaxPool2d(2, stride=2)\n",
        "        # )\n",
        "\n",
        "        self.feature_extractor_part2 = nn.Sequential(\n",
        "            nn.Linear(50 * 53 * 53, self.L),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(self.L, self.D),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(self.D, self.K)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.L*self.K, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(0)\n",
        "\n",
        "        H = self.feature_extractor_part1(x)\n",
        "        # print(H.size())\n",
        "        H = H.view(-1, 50 * 53 * 53)\n",
        "        # H = H.view(-1, 50 * 4 * 4 * 3)\n",
        "        # print(H.size())\n",
        "        # print(H.size())\n",
        "        H = self.feature_extractor_part2(H)  # NxL\n",
        "        # print(H.size())\n",
        "\n",
        "        A = self.attention(H)  # NxK\n",
        "        A = torch.transpose(A, 1, 0)  # KxN\n",
        "        A = F.softmax(A, dim=1)  # softmax over N\n",
        "\n",
        "        M = torch.mm(A, H)  # KxL\n",
        "\n",
        "        Y_prob = self.classifier(M)\n",
        "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
        "\n",
        "        return Y_prob, Y_hat, A\n",
        "\n",
        "    # AUXILIARY METHODS\n",
        "    def calculate_classification_error(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        _, Y_hat, _ = self.forward(X)\n",
        "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
        "\n",
        "        return error, Y_hat\n",
        "\n",
        "    def calculate_objective(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        Y_prob, _, A = self.forward(X)\n",
        "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
        "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
        "\n",
        "        return neg_log_likelihood, A\n",
        "    # AUXILIARY METHODS\n",
        "    def calculate_classification_error_and_objective(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        Y_prob_roc, Y_hat, A = self.forward(X)\n",
        "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
        "        Y_prob = torch.clamp(Y_prob_roc, min=1e-5, max=1. - 1e-5)\n",
        "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
        "\n",
        "\n",
        "        return neg_log_likelihood, A, Y_prob_roc.detach().cpu().float(), error, Y_hat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe3OfDuMkmZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f719f91-2bd5-49d5-b9a2-2d59713ae5e5"
      },
      "source": [
        "cuda = torch.device('cuda:0')\n",
        "attention_model = attention_lenet()\n",
        "attention_model = attention_model.to(cuda)\n",
        "summary(attention_model, (3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 20, 220, 220]           1,520\n",
            "              ReLU-2         [-1, 20, 220, 220]               0\n",
            "         MaxPool2d-3         [-1, 20, 110, 110]               0\n",
            "            Conv2d-4         [-1, 50, 106, 106]          25,050\n",
            "              ReLU-5         [-1, 50, 106, 106]               0\n",
            "         MaxPool2d-6           [-1, 50, 53, 53]               0\n",
            "            Linear-7                  [-1, 500]      70,225,500\n",
            "              ReLU-8                  [-1, 500]               0\n",
            "            Linear-9                  [-1, 128]          64,128\n",
            "             Tanh-10                  [-1, 128]               0\n",
            "           Linear-11                    [-1, 1]             129\n",
            "           Linear-12                    [-1, 1]             501\n",
            "          Sigmoid-13                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 70,316,828\n",
            "Trainable params: 70,316,828\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 26.27\n",
            "Params size (MB): 268.24\n",
            "Estimated Total Size (MB): 295.08\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3nRA5djkn2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ccd58c8-a72e-43b7-dea9-5159964dcadc"
      },
      "source": [
        "print(attention_model)\n",
        "del attention_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_lenet(\n",
            "  (feature_extractor_part1): Sequential(\n",
            "    (0): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (feature_extractor_part2): Sequential(\n",
            "    (0): Linear(in_features=140450, out_features=500, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (attention): Sequential(\n",
            "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=500, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UapbsvA2OrQ"
      },
      "source": [
        "## Learning rate study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGo798Rn2SWo"
      },
      "source": [
        "### lr=5e-8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_5Zcac22rpT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20545ad2-511a-4d8f-b669-8f48f1bd6633"
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
        "print(current_time)\n",
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Lenet/lr=5e-8'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_lenet()\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-8, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0504-1018\n",
            "the number of training sample is 40, the number of valisation sample is 8\n",
            "Epoch 0/2\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "End of phase: the true positve is 17.0, false positive is 10.0, true negative is 3.0, false negative is 10.0\n",
            "Roc calculation result: fpr is [0.         0.         0.         0.07692308 0.07692308 0.23076923\n",
            " 0.23076923 0.30769231 0.30769231 0.53846154 0.53846154 0.69230769\n",
            " 0.69230769 0.92307692 0.92307692 1.         1.        ], tpr is [0.         0.03703704 0.07407407 0.07407407 0.22222222 0.22222222\n",
            " 0.33333333 0.33333333 0.55555556 0.55555556 0.59259259 0.59259259\n",
            " 0.62962963 0.62962963 0.66666667 0.66666667 1.        ]\n",
            "fpr is [0.         0.         0.         0.07692308 0.07692308 0.23076923\n",
            " 0.23076923 0.30769231 0.30769231 0.53846154 0.53846154 0.69230769\n",
            " 0.69230769 0.92307692 0.92307692 1.         1.        ], type is float64, tpr is [0.         0.03703704 0.07407407 0.07407407 0.22222222 0.22222222\n",
            " 0.33333333 0.33333333 0.55555556 0.55555556 0.59259259 0.59259259\n",
            " 0.62962963 0.62962963 0.66666667 0.66666667 1.        ], type is <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "End of phase: the true positve is 5.0, false positive is 0.0, true negative is 0.0, false negative is 3.0\n",
            "Roc calculation result: fpr is [0.         0.         0.         0.66666667 0.66666667 1.        ], tpr is [0.  0.2 0.8 0.8 1.  1. ]\n",
            "fpr is [0.         0.         0.         0.66666667 0.66666667 1.        ], type is float64, tpr is [0.  0.2 0.8 0.8 1.  1. ], type is <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "better epoch_phase_acc is 0.625\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "train start\n",
            "End of phase: the true positve is 27.0, false positive is 0.0, true negative is 0.0, false negative is 13.0\n",
            "Roc calculation result: fpr is [0.         0.         0.         0.23076923 0.23076923 0.30769231\n",
            " 0.30769231 0.46153846 0.46153846 0.53846154 0.53846154 0.69230769\n",
            " 0.69230769 0.76923077 0.76923077 0.84615385 0.84615385 0.92307692\n",
            " 0.92307692 1.        ], tpr is [0.         0.03703704 0.51851852 0.51851852 0.55555556 0.55555556\n",
            " 0.62962963 0.62962963 0.66666667 0.66666667 0.7037037  0.7037037\n",
            " 0.77777778 0.77777778 0.81481481 0.81481481 0.92592593 0.92592593\n",
            " 1.         1.        ]\n",
            "fpr is [0.         0.         0.         0.23076923 0.23076923 0.30769231\n",
            " 0.30769231 0.46153846 0.46153846 0.53846154 0.53846154 0.69230769\n",
            " 0.69230769 0.76923077 0.76923077 0.84615385 0.84615385 0.92307692\n",
            " 0.92307692 1.        ], type is float64, tpr is [0.         0.03703704 0.51851852 0.51851852 0.55555556 0.55555556\n",
            " 0.62962963 0.62962963 0.66666667 0.66666667 0.7037037  0.7037037\n",
            " 0.77777778 0.77777778 0.81481481 0.81481481 0.92592593 0.92592593\n",
            " 1.         1.        ], type is <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "val start\n",
            "End of phase: the true positve is 5.0, false positive is 0.0, true negative is 0.0, false negative is 3.0\n",
            "Roc calculation result: fpr is [0.         0.         0.         0.66666667 0.66666667 1.        ], tpr is [0.  0.2 0.8 0.8 1.  1. ]\n",
            "fpr is [0.         0.         0.         0.66666667 0.66666667 1.        ], type is float64, tpr is [0.  0.2 0.8 0.8 1.  1. ], type is <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 0m 42s\n",
            "Best val Acc: 0.625000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxW8oUjF2YSJ"
      },
      "source": [
        "### lr=5e-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_XJJZnd3oux"
      },
      "source": [
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Lenet/lr=5e-7'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_lenet()\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-7, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV_sHdwU3r48"
      },
      "source": [
        "### lr=5e-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2srcfzAa3p33"
      },
      "source": [
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Lenet/lr=5e-6'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_lenet()\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-6, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mdcGezt3xRj"
      },
      "source": [
        "### lr=5e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWn-1iB33qH-"
      },
      "source": [
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Lenet/lr=5e-5'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_lenet()\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_KFVMYQ31sE"
      },
      "source": [
        "### lr=5e-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TFgp3LL3qXr"
      },
      "source": [
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Lenet/lr=5e-3'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_lenet()\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-3, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_riw0LC4Es2"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqmjOXi4kuH1"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "%tensorboard --logdir logs/learning_rate/0427-2004/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxzcxJLMcY1l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzDFiZMgEsOo"
      },
      "source": [
        "## Full training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjrS8g2PEww9"
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
        "log_dir = 'logs/full_epochs/' + current_time +'/Attention_Lenet/lr=5e-5'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_lenet()\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=260)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qf0r8FaFNLe"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "%tensorboard --logdir logs/full_epochs/0427-1810"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y915HLUnFRwX"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n2U7B-iFZ7b"
      },
      "source": [
        "hyper_parameters = {\n",
        "    # Training Control Parameters\n",
        "    \n",
        "    # Dataset Parameters\n",
        "    'max_bag_size': 200,\n",
        "    'dataset_max_size': None,\n",
        "    'with_data_augmentation': False,\n",
        "    # 'with_tensorboard': not args.no_tensorboard,\n",
        "    'seed': 123,\n",
        "    # 'val_size': 0.15,\n",
        "    # 'test_size': 0,\n",
        "    'val_size': 0.02,\n",
        "    'test_size': 0.95,\n",
        "}\n",
        "\n",
        "logger = None\n",
        "input_width = 224\n",
        "train_dataset, val_dataset, test_dataset, whole_cases_ids, whole_indexes, whole_dataset = build_datasets(source_slides_folders=slides_folders,\n",
        "                                                              model_input_width=input_width,\n",
        "                                                              hyper_parameters=hyper_parameters,\n",
        "                                                              logger=logger)\n",
        "N_PROCESSES = 5\n",
        "def to_dataloader(dataset, for_training):\n",
        "    assert isinstance(dataset, Dataset) or isinstance(dataset, torch.utils.data.Subset)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=for_training, num_workers=N_PROCESSES)\n",
        "\n",
        "train_dataloader = to_dataloader(train_dataset, True)\n",
        "val_dataloader = to_dataloader(val_dataset, False) if len(val_dataset) else None\n",
        "test_dataloader = to_dataloader(test_dataset, False) if len(test_dataset) else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ6gM9ZyFaU1"
      },
      "source": [
        "train_carcinoma = 0\n",
        "train_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(train_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      train_carcinoma += 1\n",
        "    else:\n",
        "      train_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the training set\" %(train_carcinoma, train_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "val_carcinoma = 0\n",
        "val_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(val_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      val_carcinoma += 1\n",
        "    else:\n",
        "      val_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the validation set\" %(val_carcinoma, val_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "test_carcinoma = 0\n",
        "test_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(test_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      test_carcinoma += 1\n",
        "    else:\n",
        "      test_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the test set\" %(test_carcinoma, test_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV6gTJHAFaa1"
      },
      "source": [
        "final = test(return_model, optimizer, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCSAL9QIkwRo"
      },
      "source": [
        "# 4.Attention-MIL (Resnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsvvwGMp0rR6"
      },
      "source": [
        "## Train and test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBMbgd9xkxkd"
      },
      "source": [
        "def train_attention(model, optimizer, train_loader, val_loader, writer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_size = train_loader.dataset.__len__()\n",
        "    val_size = val_loader.dataset.__len__()\n",
        "    print(f\"the number of training sample is {train_size}, the number of valisation sample is {val_size}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        expect_fpr = np.zeros((num_epochs, 1))\n",
        "        expect_tpr = np.zeros((num_epochs, 1))\n",
        "        roc_fpr = np.zeros((3, num_epochs))\n",
        "        roc_tpr = np.zeros((3, num_epochs))\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            train_loss = 0.\n",
        "            train_error = 0.\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            # running_loss = 0.0\n",
        "            # running_corrects = 0\n",
        "            # dataset_size_count = 0\n",
        "\n",
        "            true_positve = 0.0\n",
        "            false_positive = 0.0\n",
        "            true_negative = 0.0\n",
        "            false_negative = 0.0\n",
        "            y_true = []\n",
        "            y_predict = []\n",
        "\n",
        "            # Iterate over data.\n",
        "            for batch_idx, (data, bag_label) in enumerate(dataloader):\n",
        "            # for inputs, labels in dataloader:\n",
        "                print(phase + \" start\")\n",
        "                # dataset_size_count += data.shape[0]\n",
        "                # # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                data, bag_label = data.cuda(), bag_label.cuda()\n",
        "                # data, bag_label = data.to(dev), bag_label.to(dev)\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # calculate loss and metrics\n",
        "                    # loss, _, Y_prob_roc = model.calculate_objective(data, bag_label)\n",
        "                    # train_loss += loss.data[0].cpu().float()\n",
        "\n",
        "                    # error, _ = model.calculate_classification_error(data, bag_label)\n",
        "                    # train_error += error\n",
        "\n",
        "                    loss, _, Y_prob_roc, error, _ = model.calculate_classification_error_and_objective(data, bag_label)\n",
        "                    # print(f\"loss is {loss}\")\n",
        "                    train_loss += torch.squeeze(loss.data[0]).cpu().float()\n",
        "                    # print(f\"trin loss is {train_loss}\")\n",
        "                    train_error += error\n",
        "\n",
        "                    if bag_label == 1:\n",
        "                      y_true.append(1)\n",
        "                      if error == 0.0:\n",
        "                        true_positve += 1\n",
        "                      elif error == 1.0:\n",
        "                        false_positive += 1\n",
        "                    elif bag_label == 0:\n",
        "                      y_true.append(0)\n",
        "                      if error == 0.0:\n",
        "                        true_negative += 1\n",
        "                      elif error == 1.0:\n",
        "                        false_negative += 1\n",
        "                    # print(Y_prob_roc)\n",
        "                    y_predict.append(Y_prob_roc)\n",
        "                    \n",
        "                    # print(\"free memory\")\n",
        "                    del data, bag_label\n",
        "                    \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "            print(f\"End of phase: the true positve is {true_positve}, false positive is {false_positive}, true negative is {true_negative}, false negative is {false_negative}\")\n",
        "            # if phase == 'train':\n",
        "            #   try:\n",
        "            #     print(f\"Explicit result: fpr is {true_negative/(true_negative + false_positive)}, tpr is {true_positve/(true_positve + false_negative)}\")\n",
        "            #     expect_fpr[epoch] = (true_negative/(true_negative + false_positive))\n",
        "            #     expect_tpr[epoch] = (true_positve/(true_positve + false_negative))\n",
        "            #     print(f\"y_true is {y_true}, y_predict is {y_predict}\")\n",
        "            #   except ZeroDivisionError:\n",
        "            #     print(\"zero devision occurs\")\n",
        "            \n",
        "            fpr, tpr, _ = roc_curve(y_true, y_predict)\n",
        "            print(f\"Roc calculation result: fpr is {fpr}, tpr is {tpr}\")\n",
        "            # roc_fpr[:, epoch] = fpr\n",
        "            # roc_tpr[:, epoch] = tpr\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.figure()\n",
        "            lw = 2\n",
        "            plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "            plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "            plt.xlim([0.0, 1.0])\n",
        "            plt.ylim([0.0, 1.05])\n",
        "            plt.xlabel('False Positive Rate')\n",
        "            plt.ylabel('True Positive Rate')\n",
        "            plt.title('Receiver operating characteristic example')\n",
        "            plt.legend(loc=\"lower right\")\n",
        "            plt.show()\n",
        "            #   # if phase == 'train':\n",
        "            #   #     scheduler.step()\n",
        "\n",
        "            # dataset_sizes = dataloader.dataset.__len__()\n",
        "            # epoch_loss = running_loss / dataset_sizes\n",
        "            # # epoch_acc = running_corrects.double() / dataset_sizes\n",
        "            # epoch_acc = running_corrects / dataset_size_count\n",
        "            \n",
        "            # # print('Phase {}'.format(phase))\n",
        "            # # print(\"Loss: \")\n",
        "            # # print(train_loss)\n",
        "            # # print(\"Error: \")\n",
        "            # # print(train_error)\n",
        "\n",
        "            # # print('{} Loss: {:.4f} error: {:.4f} by Size: {:.4f}'.format(\n",
        "            # #     phase, train_loss, train_error, dataset_sizes))\n",
        "            epoch_phase_acc = 1 - (train_error / dataloader.dataset.__len__())\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val':\n",
        "              epoch_phase_acc = 1 - (train_error / dataloader.dataset.__len__())\n",
        "              if epoch_phase_acc > best_acc:\n",
        "                print(f\"better epoch_phase_acc is {epoch_phase_acc}\")\n",
        "                best_acc = epoch_phase_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            # print(f\"train loss before {train_loss}\")\n",
        "            # train_loss = torch.squeeze(train_loss)\n",
        "            # print(f\"train loss after {train_loss}\")\n",
        "            with writer.as_default():\n",
        "              if phase == 'val':\n",
        "                tf.summary.scalar('Loss/Validation', train_loss, step=epoch)\n",
        "                tf.summary.scalar('Error/Validation', train_error, step=epoch)\n",
        "              else:\n",
        "                tf.summary.scalar('Loss/Train', train_loss, step=epoch)\n",
        "                tf.summary.scalar('Error/Train', train_error, step=epoch)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    writer.close()\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7JXGIhc0e91"
      },
      "source": [
        "def test(model, optimizer, test_loader):\n",
        "    since = time.time()\n",
        "    test_size = test_loader.dataset.__len__()\n",
        "    print(f\"the number of test sample is {test_size}\")\n",
        "\n",
        "\n",
        "    # Test phase\n",
        "\n",
        "    train_error = 0.0\n",
        "    true_positve = 0.0\n",
        "    false_positive = 0.0\n",
        "    true_negative = 0.0\n",
        "    false_negative = 0.0\n",
        "    y_true = []\n",
        "    y_predict = []\n",
        "    for batch_idx, (data, bag_label) in enumerate(test_loader):\n",
        "        print(\"test start\")\n",
        "        optimizer.zero_grad()\n",
        "        data, bag_label = data.cuda(), bag_label.cuda()\n",
        "        with torch.no_grad():\n",
        "            loss, _, Y_prob_roc, error, _ = model.calculate_classification_error_and_objective(data, bag_label)\n",
        "            train_error += error\n",
        "            if bag_label == 1:\n",
        "              y_true.append(1)\n",
        "              if error == 0.0:\n",
        "                true_positve += 1\n",
        "              elif error == 1.0:\n",
        "                false_positive += 1\n",
        "            elif bag_label == 0:\n",
        "              y_true.append(0)\n",
        "              if error == 0.0:\n",
        "                true_negative += 1\n",
        "              elif error == 1.0:\n",
        "                false_negative += 1\n",
        "            # print(Y_prob_roc)\n",
        "            y_predict.append(Y_prob_roc)\n",
        "\n",
        "            # print(\"free memory\")\n",
        "            del data, bag_label\n",
        "    print(f\"End of phase: the true positve is {true_positve}, false positive is {false_positive}, true negative is {true_negative}, false negative is {false_negative}\")\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_predict)\n",
        "    print(f\"Roc calculation result: fpr is {fpr}, tpr is {tpr}\")\n",
        "    # roc_fpr[:, epoch] = fpr\n",
        "    # roc_tpr[:, epoch] = tpr\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    test_acc = 1 - (train_error / test_loader.dataset.__len__())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Test complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Test Acc: {:4f}'.format(test_acc))\n",
        "    # load best model weights\n",
        "    # model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bE8SK9vk2o7"
      },
      "source": [
        "## Dataset split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mWxeOQtk4K9"
      },
      "source": [
        "hyper_parameters = {\n",
        "    # Training Control Parameters\n",
        "    \n",
        "    # Dataset Parameters\n",
        "    'max_bag_size': 200,\n",
        "    'dataset_max_size': None,\n",
        "    'with_data_augmentation': False,\n",
        "    # 'with_tensorboard': not args.no_tensorboard,\n",
        "    'seed': 123,\n",
        "    'val_size': 0.15,\n",
        "    'test_size': 0,\n",
        "    # 'val_size': 0.02,\n",
        "    # 'test_size': 0.95,\n",
        "}\n",
        "\n",
        "logger = None\n",
        "input_width = 224\n",
        "train_dataset, val_dataset, test_dataset, whole_cases_ids, whole_indexes, whole_dataset = build_datasets(source_slides_folders=slides_folders,\n",
        "                                                              model_input_width=input_width,\n",
        "                                                              hyper_parameters=hyper_parameters,\n",
        "                                                              logger=logger)\n",
        "N_PROCESSES = 5\n",
        "def to_dataloader(dataset, for_training):\n",
        "    assert isinstance(dataset, Dataset) or isinstance(dataset, torch.utils.data.Subset)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=for_training, num_workers=N_PROCESSES)\n",
        "\n",
        "train_dataloader = to_dataloader(train_dataset, True)\n",
        "val_dataloader = to_dataloader(val_dataset, False) if len(val_dataset) else None\n",
        "test_dataloader = to_dataloader(test_dataset, False) if len(test_dataset) else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkvue1Mzk5z6"
      },
      "source": [
        "train_carcinoma = 0\n",
        "train_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(train_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      train_carcinoma += 1\n",
        "    else:\n",
        "      train_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the training set\" %(train_carcinoma, train_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "val_carcinoma = 0\n",
        "val_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(val_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      val_carcinoma += 1\n",
        "    else:\n",
        "      val_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the validation set\" %(val_carcinoma, val_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "test_carcinoma = 0\n",
        "test_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(test_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      test_carcinoma += 1\n",
        "    else:\n",
        "      test_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the test set\" %(test_carcinoma, test_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qQFhrUgk9Yr"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7I-YwZzk_Ut"
      },
      "source": [
        "class attention_resnet(nn.Module):\n",
        "    def __init__(self,output_layer = None):\n",
        "        super().__init__()\n",
        "        self.pretrained = models.resnet18(pretrained=True)\n",
        "        self.output_layer = output_layer\n",
        "        self.layers = list(self.pretrained._modules.keys())\n",
        "        self.layer_count = 0\n",
        "        for l in self.layers:\n",
        "            if l != self.output_layer:\n",
        "                self.layer_count += 1\n",
        "            else:\n",
        "                break\n",
        "        for i in range(1,len(self.layers)-self.layer_count):\n",
        "            self.dummy_var = self.pretrained._modules.pop(self.layers[-i])\n",
        "        \n",
        "        self.net = nn.Sequential(self.pretrained._modules)\n",
        "        self.pretrained = None\n",
        "\n",
        "        self.L = 500\n",
        "        self.D = 128\n",
        "        self.K = 1\n",
        "\n",
        "# N, 512, 7, 7\n",
        "\n",
        "        self.feature_extractor_attention = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, self.L),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(self.L, self.D),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(self.D, self.K)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.L*self.K, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.squeeze(0)\n",
        "        x = self.net(x)\n",
        "        # print(\"x size 1\")\n",
        "        # print(x.size())\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "\n",
        "        H = self.feature_extractor_attention(x)\n",
        "\n",
        "        A = self.attention(H)  # NxK\n",
        "        A = torch.transpose(A, 1, 0)  # KxN\n",
        "        A = F.softmax(A, dim=1)  # softmax over N\n",
        "\n",
        "        M = torch.mm(A, H)  # KxL\n",
        "\n",
        "        Y_prob = self.classifier(M)\n",
        "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
        "\n",
        "        return Y_prob, Y_hat, A\n",
        "    \n",
        "    # AUXILIARY METHODS\n",
        "    def calculate_classification_error(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        _, Y_hat, _ = self.forward(X)\n",
        "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
        "\n",
        "        return error, Y_hat\n",
        "\n",
        "    def calculate_objective(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        Y_prob, _, A = self.forward(X)\n",
        "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
        "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
        "\n",
        "        return neg_log_likelihood, A\n",
        "    \n",
        "    # AUXILIARY METHODS\n",
        "    def calculate_classification_error_and_objective(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        Y_prob_roc, Y_hat, A = self.forward(X)\n",
        "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
        "        Y_prob = torch.clamp(Y_prob_roc, min=1e-5, max=1. - 1e-5)\n",
        "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
        "\n",
        "\n",
        "        return neg_log_likelihood, A, Y_prob_roc.detach().cpu().float(), error, Y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0dD0n2klVQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "95a1ee7a33cd444782da951732c6927d",
            "a42d54b74e00438d9bea1281fe9d640d",
            "939c34518f744a55a8cb788dd8641b4a",
            "fc3ab5934ebb4807bb5aced6628c1913",
            "8468866baa884b89b7db49a6c6b4168e",
            "ef8ec5baaa1e4c389112ff792948d517",
            "42de22943ad14ee8b4c30c02be0f7468",
            "3f426bd794fb497b85ab377293291bbb"
          ]
        },
        "outputId": "391f5109-cd73-4b78-c8c2-02e6b4fe7c5a"
      },
      "source": [
        "model = attention_resnet(output_layer = 'layer4')\n",
        "cuda = torch.device('cuda:0')\n",
        "model = model.to(cuda)\n",
        "summary(model,input_size=(3, 224, 224))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a1ee7a33cd444782da951732c6927d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "           Linear-67                  [-1, 500]      12,544,500\n",
            "             ReLU-68                  [-1, 500]               0\n",
            "           Linear-69                  [-1, 128]          64,128\n",
            "             Tanh-70                  [-1, 128]               0\n",
            "           Linear-71                    [-1, 1]             129\n",
            "           Linear-72                    [-1, 1]             501\n",
            "          Sigmoid-73                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 23,785,770\n",
            "Trainable params: 23,785,770\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 90.74\n",
            "Estimated Total Size (MB): 154.10\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRwXJoajqB4B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z390rbNAlZFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b36fdf-380b-4425-8079-fd8673d4fa63"
      },
      "source": [
        "print(model)\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_resnet(\n",
            "  (pretrained): None\n",
            "  (dummy_var): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (net): Sequential(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (feature_extractor_attention): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=500, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (attention): Sequential(\n",
            "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=500, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLBZ7V43ldyf"
      },
      "source": [
        "## Learning rate study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i718xNcJlgYF"
      },
      "source": [
        "### lr=5e-8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPS2wOz_la-b"
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
        "print(current_time)\n",
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Resnet/lr=5e-8'\n",
        "\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-8, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a37QI4aelpPx"
      },
      "source": [
        "### lr=5e-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqT6eVS_lvPP"
      },
      "source": [
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Resnet/lr=5e-7'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-7, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5HLd5iqlqy-"
      },
      "source": [
        "### lr=5e-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLb7bbDJlws3"
      },
      "source": [
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Resnet/lr=5e-6'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-6, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_wupUyvlsXB"
      },
      "source": [
        "### lr=5e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWvbn2eXlz98"
      },
      "source": [
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Resnet/lr=5e-5'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4USqozUkltnL"
      },
      "source": [
        "### lr=5e-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCyrlplHl1-3"
      },
      "source": [
        "log_dir = 'logs/learning_rate/' + current_time +'/Attention_Resnet/lr=5e-3'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-3, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=30)\n",
        "del return_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO_vRXu7l6cr"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjlpAZShl62I"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "%tensorboard --logdir logs/learning_rate/0427-1624/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umbacxAqmYYi"
      },
      "source": [
        "## Full epochs Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tqPhuzHp3dJ"
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
        "print(current_time)\n",
        "log_dir = 'logs/full_epochs/' + current_time +'/Attention_Resnet/lr=5e-6'\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "model = attention_resnet(output_layer = 'layer4')\n",
        "model = model.to(cuda)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-6, betas=(0.9, 0.999), weight_decay=0.001)\n",
        "\n",
        "return_model = train_attention(model, optimizer, train_dataloader, val_dataloader, summary_writer, num_epochs=70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6wxHvZgqeA8"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "%tensorboard --logdir logs/full_epochs/0427-1721/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgiqcRAintBH"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da0ExX_tntBI"
      },
      "source": [
        "hyper_parameters = {\n",
        "    # Training Control Parameters\n",
        "    \n",
        "    # Dataset Parameters\n",
        "    'max_bag_size': 200,\n",
        "    'dataset_max_size': None,\n",
        "    'with_data_augmentation': False,\n",
        "    # 'with_tensorboard': not args.no_tensorboard,\n",
        "    'seed': 123,\n",
        "    # 'val_size': 0.15,\n",
        "    # 'test_size': 0,\n",
        "    'val_size': 0.02,\n",
        "    'test_size': 0.95,\n",
        "}\n",
        "\n",
        "logger = None\n",
        "input_width = 224\n",
        "train_dataset, val_dataset, test_dataset, whole_cases_ids, whole_indexes, whole_dataset = build_datasets(source_slides_folders=slides_folders,\n",
        "                                                              model_input_width=input_width,\n",
        "                                                              hyper_parameters=hyper_parameters,\n",
        "                                                              logger=logger)\n",
        "N_PROCESSES = 5\n",
        "def to_dataloader(dataset, for_training):\n",
        "    assert isinstance(dataset, Dataset) or isinstance(dataset, torch.utils.data.Subset)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=for_training, num_workers=N_PROCESSES)\n",
        "\n",
        "train_dataloader = to_dataloader(train_dataset, True)\n",
        "val_dataloader = to_dataloader(val_dataset, False) if len(val_dataset) else None\n",
        "test_dataloader = to_dataloader(test_dataset, False) if len(test_dataset) else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUB-w5isntBJ"
      },
      "source": [
        "train_carcinoma = 0\n",
        "train_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(train_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      train_carcinoma += 1\n",
        "    else:\n",
        "      train_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the training set\" %(train_carcinoma, train_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "val_carcinoma = 0\n",
        "val_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(val_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      val_carcinoma += 1\n",
        "    else:\n",
        "      val_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the validation set\" %(val_carcinoma, val_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")\n",
        "\n",
        "test_carcinoma = 0\n",
        "test_non_carcinoma = 0\n",
        "try:\n",
        "  for batch_idx, (data, bag_label) in enumerate(test_dataloader):\n",
        "    if bag_label == torch.Tensor([0]):\n",
        "      test_carcinoma += 1\n",
        "    else:\n",
        "      test_non_carcinoma += 1\n",
        "  print(\"There are %d carcinoma and %d non-carcinoma samples in the test set\" %(test_carcinoma, test_non_carcinoma))\n",
        "except TypeError:\n",
        "  print(\"Nan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNmDyC1EntBJ"
      },
      "source": [
        "final = test(return_model, optimizer, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}